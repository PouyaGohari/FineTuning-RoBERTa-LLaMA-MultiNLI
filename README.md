# FineTuning-RoBERTa-LLaMA-MultiNLI-
This repository contains the implementation and analysis of various fine-tuning techniques applied to RoBERTa and LLaMA models on the MultiNLI dataset. The project is part of the fourth computer assignment for the Natural Language Processing course at the University of Tehran.
