{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-01T21:09:57.102152Z","iopub.status.busy":"2024-06-01T21:09:57.101792Z","iopub.status.idle":"2024-06-01T21:10:41.944350Z","shell.execute_reply":"2024-06-01T21:10:41.943403Z","shell.execute_reply.started":"2024-06-01T21:09:57.102120Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting peft\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.41.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.1)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: peft\n","Successfully installed peft-0.11.1\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\n","\u001b[0m\u001b[31m\n","\u001b[0mCollecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install peft\n","!pip install datasets\n","!pip install bitsandbytes\n","!pip install accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:41.946639Z","iopub.status.busy":"2024-06-01T21:10:41.946309Z","iopub.status.idle":"2024-06-01T21:10:49.199988Z","shell.execute_reply":"2024-06-01T21:10:49.199232Z","shell.execute_reply.started":"2024-06-01T21:10:41.946610Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, PreTrainedModel, LlamaPreTrainedModel, LlamaModel, AutoConfig\n","\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n","from datasets import load_dataset\n","from huggingface_hub import notebook_login\n","import torch\n","from transformers.modeling_outputs import SequenceClassifierOutputWithPast"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:49.202122Z","iopub.status.busy":"2024-06-01T21:10:49.201648Z","iopub.status.idle":"2024-06-01T21:10:49.209177Z","shell.execute_reply":"2024-06-01T21:10:49.208243Z","shell.execute_reply.started":"2024-06-01T21:10:49.202093Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:49.210733Z","iopub.status.busy":"2024-06-01T21:10:49.210375Z","iopub.status.idle":"2024-06-01T21:10:49.218937Z","shell.execute_reply":"2024-06-01T21:10:49.218061Z","shell.execute_reply.started":"2024-06-01T21:10:49.210706Z"},"trusted":true},"outputs":[],"source":["model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","dataset_name = \"multi_nli\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:49.220858Z","iopub.status.busy":"2024-06-01T21:10:49.220566Z","iopub.status.idle":"2024-06-01T21:10:49.244871Z","shell.execute_reply":"2024-06-01T21:10:49.243912Z","shell.execute_reply.started":"2024-06-01T21:10:49.220824Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"002c4fe1791f4b5baff0cd934c971946","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_login()\n","#"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:57.639278Z","iopub.status.busy":"2024-06-01T21:10:57.638898Z","iopub.status.idle":"2024-06-01T21:10:58.729854Z","shell.execute_reply":"2024-06-01T21:10:58.728800Z","shell.execute_reply.started":"2024-06-01T21:10:57.639248Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1e1432c11fb4c1aa469f03e62599d77","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"857d3846e6904cf5b0ed9df1d20e8c66","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"339bc3e9337d44b1b08c45501cd5d74b","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_eos_token = True"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:58.945091Z","iopub.status.busy":"2024-06-01T21:10:58.944336Z","iopub.status.idle":"2024-06-01T21:10:59.001037Z","shell.execute_reply":"2024-06-01T21:10:59.000293Z","shell.execute_reply.started":"2024-06-01T21:10:58.945036Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import bitsandbytes as bnb\n","from torch.nn import CrossEntropyLoss\n","class CLF(LlamaPreTrainedModel):\n","    def __init__(self, config, num_labels):\n","        super().__init__(config)\n","        self.num_labels = num_labels\n","        self.model = LlamaModel(config)\n","        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n","        self.post_init()\n","    \n","    def forward(self, input_ids=None,\n","                attention_mask=None,\n","                labels=None,\n","                position_ids=None,\n","                past_key_values=None,\n","                inputs_embeds=None,\n","                use_cache=None,\n","                output_attentions=None,\n","                output_hidden_states=None,\n","                return_dict=None):        \n","        \n","        transformers_outputs = self.model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                position_ids=position_ids,\n","                past_key_values=past_key_values,\n","                inputs_embeds=inputs_embeds,\n","                use_cache=use_cache,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict)\n","\n","        hidden_states = transformers_outputs.last_hidden_state\n","        logits = self.score(hidden_states)\n","        \n","        batch_size = input_ids.shape[0]\n","        \n","        sequence_lengths = torch.eq(input_ids, self.config.pad_token_id).int().argmax(-1) - 1\n","        sequence_lengths = sequence_lengths % input_ids.shape[-1]\n","        sequence_lengths = sequence_lengths.to(logits.device)\n","        pooled_logits = logits[torch.arange(batch_size, device=logits.device), sequence_lengths]\n","        \n","        loss = None\n","        if labels is not None:\n","            labels = labels.to(logits.device)\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n","        \n","        if not return_dict:\n","            output = (pooled_logits,) + transformer_outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","        \n","        return SequenceClassifierOutputWithPast(\n","            loss=loss,\n","            logits=pooled_logits,\n","            past_key_values=transformers_outputs.past_key_values,\n","            hidden_states=transformers_outputs.hidden_states,\n","            attentions=transformers_outputs.attentions,\n","        )"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:10:59.798000Z","iopub.status.busy":"2024-06-01T21:10:59.797405Z","iopub.status.idle":"2024-06-01T21:10:59.960575Z","shell.execute_reply":"2024-06-01T21:10:59.959452Z","shell.execute_reply.started":"2024-06-01T21:10:59.797970Z"},"trusted":true},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit= True,\n","    bnb_4bit_quant_type= \"nf4\",\n","    bnb_4bit_compute_dtype= torch.float16,\n","    bnb_4bit_use_double_quant= False,\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:11:00.355816Z","iopub.status.busy":"2024-06-01T21:11:00.355426Z","iopub.status.idle":"2024-06-01T21:11:00.360713Z","shell.execute_reply":"2024-06-01T21:11:00.359762Z","shell.execute_reply.started":"2024-06-01T21:11:00.355782Z"},"trusted":true},"outputs":[],"source":["num_labels = 3\n","id2label = {0: 'entailment', 1: 'contradiction', 2: 'neutral'}\n","label2id = {label: idx for idx, label in id2label.items()}"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:11:01.305192Z","iopub.status.busy":"2024-06-01T21:11:01.304515Z","iopub.status.idle":"2024-06-01T21:13:30.749416Z","shell.execute_reply":"2024-06-01T21:13:30.748400Z","shell.execute_reply.started":"2024-06-01T21:11:01.305159Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f647bfa62e9940fc8d9735547486a91a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56b003c63fd14e21a283c205bc239c07","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dd980c8a959453ead417b26780b7cdb","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"215c8972fb1e4561a037d70ecf7a87f7","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6b3a2dc23f34b47ab504cc7c16108fd","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e07190a67c543f08176edcbfc143434","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b105e53932ab4b9ea2f5590db71ad3b3","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77e8839233fd4068b9eec9149ae3122b","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of CLF were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B-Instruct and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["config = AutoConfig.from_pretrained(model_name, num_labels=len(id2label))\n","config.id2label = id2label\n","config.label2id = label2id\n","config.pad_token_id = tokenizer.pad_token_id\n","model = CLF.from_pretrained(\n","    model_name,\n","    config=config,\n","    num_labels=len(id2label),\n","    quantization_config=bnb_config,\n","    torch_dtype=torch.bfloat16,\n","    attn_implementation=\"eager\",\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:33.987214Z","iopub.status.busy":"2024-06-01T21:13:33.986195Z","iopub.status.idle":"2024-06-01T21:13:34.016228Z","shell.execute_reply":"2024-06-01T21:13:34.015454Z","shell.execute_reply.started":"2024-06-01T21:13:33.987162Z"},"trusted":true},"outputs":[],"source":["model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:34.279136Z","iopub.status.busy":"2024-06-01T21:13:34.278799Z","iopub.status.idle":"2024-06-01T21:13:34.286469Z","shell.execute_reply":"2024-06-01T21:13:34.285541Z","shell.execute_reply.started":"2024-06-01T21:13:34.279109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CLF(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096, padding_idx=128009)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaAttention(\n","          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm()\n","        (post_attention_layernorm): LlamaRMSNorm()\n","      )\n","    )\n","    (norm): LlamaRMSNorm()\n","  )\n","  (score): Linear(in_features=4096, out_features=3, bias=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:34.672729Z","iopub.status.busy":"2024-06-01T21:13:34.672405Z","iopub.status.idle":"2024-06-01T21:13:34.678016Z","shell.execute_reply":"2024-06-01T21:13:34.676904Z","shell.execute_reply.started":"2024-06-01T21:13:34.672705Z"},"trusted":true},"outputs":[],"source":["peft_config = LoraConfig(\n","    lora_alpha= 16,\n","    lora_dropout= 0.05,\n","    r= 16,\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\",\n","    target_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\", \"score\"]\n","#     target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\"]\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:35.087423Z","iopub.status.busy":"2024-06-01T21:13:35.086628Z","iopub.status.idle":"2024-06-01T21:13:35.983197Z","shell.execute_reply":"2024-06-01T21:13:35.982261Z","shell.execute_reply.started":"2024-06-01T21:13:35.087390Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 42,020,912 || all params: 7,547,023,456 || trainable%: 0.5568\n"]}],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:35.985612Z","iopub.status.busy":"2024-06-01T21:13:35.984944Z","iopub.status.idle":"2024-06-01T21:13:43.515927Z","shell.execute_reply":"2024-06-01T21:13:43.515229Z","shell.execute_reply.started":"2024-06-01T21:13:35.985577Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9847e7a891b9494d8b96574c327ae21f","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/8.89k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f551b780f8a45e2bd041e1be87111d1","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/214M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bb6a2e7329a49179e4ead34cd1543d2","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/4.94M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3f2938e00514f53826493be7fa09730","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/5.10M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca10d5f71d3b46359734ff6b4d375b0a","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f987b24a2a644e8aab72fdb215e9d333","version_major":2,"version_minor":0},"text/plain":["Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09eec23ec2c34cafbe50b80282c2dae3","version_major":2,"version_minor":0},"text/plain":["Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(dataset_name)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:44.966068Z","iopub.status.busy":"2024-06-01T21:13:44.965113Z","iopub.status.idle":"2024-06-01T21:13:44.989352Z","shell.execute_reply":"2024-06-01T21:13:44.987955Z","shell.execute_reply.started":"2024-06-01T21:13:44.966029Z"},"trusted":true},"outputs":[{"data":{"text/plain":["5760475520"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model.get_memory_footprint()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:46.026932Z","iopub.status.busy":"2024-06-01T21:13:46.026584Z","iopub.status.idle":"2024-06-01T21:13:46.032197Z","shell.execute_reply":"2024-06-01T21:13:46.031309Z","shell.execute_reply.started":"2024-06-01T21:13:46.026905Z"},"trusted":true},"outputs":[],"source":["import random\n","def sample_5_percent(dataset):\n","    total_size = len(dataset)\n","    sample_size = max(1, 5 * total_size // 100)\n","    indices = random.sample(range(total_size), sample_size)\n","    return dataset.select(indices)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:47.036540Z","iopub.status.busy":"2024-06-01T21:13:47.036171Z","iopub.status.idle":"2024-06-01T21:13:47.165001Z","shell.execute_reply":"2024-06-01T21:13:47.164169Z","shell.execute_reply.started":"2024-06-01T21:13:47.036511Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((19635, 10), (490, 10))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sampled_train_dataset = sample_5_percent(dataset['train'])\n","sampled_validation_dataset = sample_5_percent(dataset['validation_matched'])\n","sampled_train_dataset.shape, sampled_validation_dataset.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:48.166847Z","iopub.status.busy":"2024-06-01T21:13:48.166489Z","iopub.status.idle":"2024-06-01T21:13:48.171013Z","shell.execute_reply":"2024-06-01T21:13:48.170085Z","shell.execute_reply.started":"2024-06-01T21:13:48.166817Z"},"trusted":true},"outputs":[],"source":["INSTRUCTION = \"Decide whether the following statements are entailment, contradiction, or neutral.\""]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:49.082246Z","iopub.status.busy":"2024-06-01T21:13:49.081289Z","iopub.status.idle":"2024-06-01T21:13:49.088168Z","shell.execute_reply":"2024-06-01T21:13:49.087100Z","shell.execute_reply.started":"2024-06-01T21:13:49.082204Z"},"trusted":true},"outputs":[],"source":["def create_prompt(example, instruction):\n","    premise = example['premise']\n","    hypothesis = example['hypothesis']\n","    user_input = f\"\\nPremise: {premise}\\nHypothesis: {hypothesis}\\n\"\n","    prompt = f\"\"\"<|start_header_id|>system<|end_header_id|> {instruction}<|eot_id|><|start_header_id|>user<|end_header_id|> Are these two statements entailment, contradiction, or neutral?: {user_input}<|eot_id|>\"\"\"\n","    return prompt"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:49.728345Z","iopub.status.busy":"2024-06-01T21:13:49.727970Z","iopub.status.idle":"2024-06-01T21:13:54.168255Z","shell.execute_reply":"2024-06-01T21:13:54.167303Z","shell.execute_reply.started":"2024-06-01T21:13:49.728318Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ff80e2fe3a14fc9893299d880df0685","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/19635 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = sampled_train_dataset.map(lambda example: {'prompt': create_prompt(example, INSTRUCTION)})"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:56.249257Z","iopub.status.busy":"2024-06-01T21:13:56.248360Z","iopub.status.idle":"2024-06-01T21:13:56.293154Z","shell.execute_reply":"2024-06-01T21:13:56.292191Z","shell.execute_reply.started":"2024-06-01T21:13:56.249221Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"<|start_header_id|>system<|end_header_id|> Decide whether the following statements are entailment, contradiction, or neutral.<|eot_id|><|start_header_id|>user<|end_header_id|> Are these two statements entailment, contradiction, or neutral?: \\nPremise: What's more, they observe something called the minimal group effect.\\nHypothesis: The minimal group effect is also observed.\\n<|eot_id|>\""]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset['prompt'][0]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:56.912181Z","iopub.status.busy":"2024-06-01T21:13:56.911241Z","iopub.status.idle":"2024-06-01T21:13:56.917836Z","shell.execute_reply":"2024-06-01T21:13:56.916796Z","shell.execute_reply.started":"2024-06-01T21:13:56.912149Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label', 'prompt'],\n","    num_rows: 19635\n","})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:57.689298Z","iopub.status.busy":"2024-06-01T21:13:57.688613Z","iopub.status.idle":"2024-06-01T21:13:57.693733Z","shell.execute_reply":"2024-06-01T21:13:57.692673Z","shell.execute_reply.started":"2024-06-01T21:13:57.689263Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    outputs = tokenizer(examples['prompt'], truncation=True, max_length=None)\n","    return outputs"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:13:58.274601Z","iopub.status.busy":"2024-06-01T21:13:58.273763Z","iopub.status.idle":"2024-06-01T21:14:00.984749Z","shell.execute_reply":"2024-06-01T21:14:00.983832Z","shell.execute_reply.started":"2024-06-01T21:13:58.274569Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0025eff52d334bbf87b01df47c7310b4","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/19635 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["train_tokenized_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"promptID\", \"pairID\", \"premise\", \"premise_binary_parse\", \"premise_parse\", \"hypothesis\", \"hypothesis_binary_parse\", \"hypothesis_parse\", \"genre\", \"prompt\"]).rename_column('label', 'labels')"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:14:00.987120Z","iopub.status.busy":"2024-06-01T21:14:00.986540Z","iopub.status.idle":"2024-06-01T21:14:00.993272Z","shell.execute_reply":"2024-06-01T21:14:00.992381Z","shell.execute_reply.started":"2024-06-01T21:14:00.987084Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 19635\n","})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["train_tokenized_dataset"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:14:03.960330Z","iopub.status.busy":"2024-06-01T21:14:03.959943Z","iopub.status.idle":"2024-06-01T21:14:03.966303Z","shell.execute_reply":"2024-06-01T21:14:03.965310Z","shell.execute_reply.started":"2024-06-01T21:14:03.960302Z"},"trusted":true},"outputs":[],"source":["class CustomDataCollator:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, features):\n","        batch = self.tokenizer.pad(\n","            features,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        )\n","        return batch"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:14:04.807678Z","iopub.status.busy":"2024-06-01T21:14:04.807320Z","iopub.status.idle":"2024-06-01T21:14:04.811952Z","shell.execute_reply":"2024-06-01T21:14:04.810975Z","shell.execute_reply.started":"2024-06-01T21:14:04.807650Z"},"trusted":true},"outputs":[],"source":["data_collator = CustomDataCollator(tokenizer)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:14:05.409685Z","iopub.status.busy":"2024-06-01T21:14:05.408927Z","iopub.status.idle":"2024-06-01T21:14:17.097032Z","shell.execute_reply":"2024-06-01T21:14:17.096061Z","shell.execute_reply.started":"2024-06-01T21:14:05.409652Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-01 21:14:07.753144: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 21:14:07.753253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 21:14:07.905701: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n","from accelerate import Accelerator\n","\n","training_args=TrainingArguments(\n","        # num_train_epochs= 1,\n","        per_device_train_batch_size=4,\n","        gradient_accumulation_steps=4,\n","        logging_steps= 30,\n","        warmup_steps=5,\n","        max_steps=240,\n","        learning_rate=2e-5,\n","        weight_decay= 0.01,\n","        fp16= False,\n","        bf16= False,\n","        max_grad_norm= 0.3,\n","        group_by_length= True,\n","        optim=\"paged_adamw_8bit\",\n","        output_dir= \"/content/drive/MyDrive/weigths\",\n","        report_to=\"none\", \n",")\n","\n","# accelerator = Accelerator()\n","# model_with_clf, tokenizer, training_args = accelerator.prepare(model_with_clf, tokenizer, training_args)\n","\n","trainer = Trainer(\n","    model=model,\n","    train_dataset=train_tokenized_dataset,\n","    args=training_args,\n","    data_collator=data_collator,\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T21:14:17.099423Z","iopub.status.busy":"2024-06-01T21:14:17.098779Z","iopub.status.idle":"2024-06-01T22:04:23.904551Z","shell.execute_reply":"2024-06-01T22:04:23.903522Z","shell.execute_reply.started":"2024-06-01T21:14:17.099394Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [240/240 49:36, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>30</td>\n","      <td>1.238900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.126600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.171900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.121700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.123400</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.114600</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.122800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.100900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=240, training_loss=1.1401063760121664, metrics={'train_runtime': 3003.4363, 'train_samples_per_second': 1.279, 'train_steps_per_second': 0.08, 'total_flos': 1.31816723460864e+16, 'train_loss': 1.1401063760121664, 'epoch': 0.1955591770217967})"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["model.train()\n","trainer.train()"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:43.845509Z","iopub.status.busy":"2024-06-01T22:05:43.844831Z","iopub.status.idle":"2024-06-01T22:05:43.884619Z","shell.execute_reply":"2024-06-01T22:05:43.883467Z","shell.execute_reply.started":"2024-06-01T22:05:43.845475Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PeftModelForSequenceClassification(\n","  (base_model): LoraModel(\n","    (model): CLF(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 4096, padding_idx=128009)\n","        (layers): ModuleList(\n","          (0-31): 32 x LlamaDecoderLayer(\n","            (self_attn): LlamaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=14336, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm()\n","            (post_attention_layernorm): LlamaRMSNorm()\n","          )\n","        )\n","        (norm): LlamaRMSNorm()\n","      )\n","      (score): ModulesToSaveWrapper(\n","        (original_module): lora.Linear(\n","          (base_layer): Linear(in_features=4096, out_features=3, bias=False)\n","          (lora_dropout): ModuleDict(\n","            (default): Dropout(p=0.05, inplace=False)\n","          )\n","          (lora_A): ModuleDict(\n","            (default): Linear(in_features=4096, out_features=16, bias=False)\n","          )\n","          (lora_B): ModuleDict(\n","            (default): Linear(in_features=16, out_features=3, bias=False)\n","          )\n","          (lora_embedding_A): ParameterDict()\n","          (lora_embedding_B): ParameterDict()\n","        )\n","        (modules_to_save): ModuleDict(\n","          (default): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=3, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=16, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=16, out_features=3, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","        )\n","      )\n","    )\n","  )\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:44.627500Z","iopub.status.busy":"2024-06-01T22:05:44.627094Z","iopub.status.idle":"2024-06-01T22:05:44.762452Z","shell.execute_reply":"2024-06-01T22:05:44.761539Z","shell.execute_reply.started":"2024-06-01T22:05:44.627469Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d24c1eb211c0420287ce33067ea51ff7","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/490 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["validation_set = sampled_validation_dataset.map(lambda example: {'prompt': create_prompt(example, INSTRUCTION)})"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:45.904882Z","iopub.status.busy":"2024-06-01T22:05:45.903906Z","iopub.status.idle":"2024-06-01T22:05:46.212047Z","shell.execute_reply":"2024-06-01T22:05:46.211052Z","shell.execute_reply.started":"2024-06-01T22:05:45.904847Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"424bfeb327fb41af9fbfca51956ce17b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/490 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_match= validation_set.map(preprocess_function, batched=True, remove_columns=[\"promptID\", \"pairID\", \"premise\", \"premise_binary_parse\", \"premise_parse\", \"hypothesis\", \"hypothesis_binary_parse\", \"hypothesis_parse\", \"genre\", \"prompt\"]).rename_column('label', 'labels')"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:46.913859Z","iopub.status.busy":"2024-06-01T22:05:46.913461Z","iopub.status.idle":"2024-06-01T22:05:46.920465Z","shell.execute_reply":"2024-06-01T22:05:46.919324Z","shell.execute_reply.started":"2024-06-01T22:05:46.913826Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 490\n","})"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["val_match"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:47.679795Z","iopub.status.busy":"2024-06-01T22:05:47.679408Z","iopub.status.idle":"2024-06-01T22:05:47.684785Z","shell.execute_reply":"2024-06-01T22:05:47.683603Z","shell.execute_reply.started":"2024-06-01T22:05:47.679767Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:49.161713Z","iopub.status.busy":"2024-06-01T22:05:49.160968Z","iopub.status.idle":"2024-06-01T22:05:49.166242Z","shell.execute_reply":"2024-06-01T22:05:49.165119Z","shell.execute_reply.started":"2024-06-01T22:05:49.161680Z"},"trusted":true},"outputs":[],"source":["val_loader = DataLoader(val_match, batch_size=4, collate_fn=data_collator)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:05:50.005339Z","iopub.status.busy":"2024-06-01T22:05:50.004563Z","iopub.status.idle":"2024-06-01T22:08:11.860734Z","shell.execute_reply":"2024-06-01T22:08:11.859890Z","shell.execute_reply.started":"2024-06-01T22:05:50.005307Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","\n","all_predictions = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for batch in val_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=-1)\n","\n","        all_predictions.extend(predictions.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:08:29.905470Z","iopub.status.busy":"2024-06-01T22:08:29.905101Z","iopub.status.idle":"2024-06-01T22:08:29.912950Z","shell.execute_reply":"2024-06-01T22:08:29.912083Z","shell.execute_reply.started":"2024-06-01T22:08:29.905443Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T22:08:30.520822Z","iopub.status.busy":"2024-06-01T22:08:30.519889Z","iopub.status.idle":"2024-06-01T22:08:30.538432Z","shell.execute_reply":"2024-06-01T22:08:30.537590Z","shell.execute_reply.started":"2024-06-01T22:08:30.520783Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.3469\n","Precision: 0.1204\n","Recall: 0.3469\n","F1 Score: 0.1787\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["accuracy = accuracy_score(all_labels, all_predictions)\n","precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
